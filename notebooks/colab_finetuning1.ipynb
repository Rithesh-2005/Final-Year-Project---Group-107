{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeedcf2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Install dependencies\n",
    "!pip install -q transformers datasets peft trl bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7e72c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Import libraries\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6b08d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Load Model (Quantized for free Colab memory limits)\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True, # Requires bitsandbytes\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81820f23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Apply LoRA (Parameter Efficient Fine-Tuning)\n",
    "lora_config = LoraConfig(\n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    target_modules=[\"q_proj\", \"v_proj\"], \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25e147",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Load Dataset (Example: mapping intent to JSON schema)\n",
    "# You should upload a custom JSONL dataset mapping 'instruction' to 'schema'\n",
    "dataset = load_dataset(\"json\", data_files=\"workflow_dataset.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f52f2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Train the Model\n",
    "trainer = SFTTrainer(\n",
    "    model=peft_model,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        save_steps=50,\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        max_steps=200\n",
    "    ),\n",
    ")\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(\"fine-tuned-workflow-llm\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
